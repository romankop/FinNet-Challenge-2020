{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import igraph\n",
    "import time\n",
    "import gc\n",
    "from os import path\n",
    "import ipython_memory_usage\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'memory profile enabled'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [2] used 0.1094 MiB RAM in 0.15s, peaked 0.00 MiB above current, total RAM usage 108.02 MiB\n"
     ]
    }
   ],
   "source": [
    "%ipython_memory_usage_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [3] used 190.8789 MiB RAM in 2.10s, peaked 81.16 MiB above current, total RAM usage 298.90 MiB\n"
     ]
    }
   ],
   "source": [
    "vertices = pd.read_csv('data\\\\vertices.csv') ## вершины ребер, то есть юр.лица\n",
    "edges = pd.read_csv('data\\\\edges.csv') ## ребра графа, то есть транзакции между юр.лицами\n",
    "test = pd.read_csv('data\\\\ids.csv')#.drop('rec_num_of_edges', axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [4] used 42.0820 MiB RAM in 0.65s, peaked 108.52 MiB above current, total RAM usage 340.98 MiB\n"
     ]
    }
   ],
   "source": [
    "rec_num_of_edges = test.merge(vertices, how = 'outer')[['id', 'rec_num_of_edges']]\n",
    "rec_num_of_edges = rec_num_of_edges.fillna(np.inf)\n",
    "rec_num_of_edges['cur_num_of_edges'] = 0\n",
    "rec_num_of_edges['id'] = rec_num_of_edges['id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [5] used 0.0273 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 341.01 MiB\n"
     ]
    }
   ],
   "source": [
    "test = test.drop('rec_num_of_edges', axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [6] used -5.0781 MiB RAM in 0.33s, peaked 16.75 MiB above current, total RAM usage 335.93 MiB\n"
     ]
    }
   ],
   "source": [
    "my_encoder = LabelEncoder()\n",
    "vertices['company_type']= my_encoder.fit_transform(vertices['company_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [7] used 76.1484 MiB RAM in 0.23s, peaked 0.00 MiB above current, total RAM usage 412.08 MiB\n"
     ]
    }
   ],
   "source": [
    "vertices['is_true'] = 0\n",
    "vert_id_istrue = vertices[['id', 'is_true']]\n",
    "vert_no_true = vertices.drop(['is_true'], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [17] used 2.3906 MiB RAM in 0.13s, peaked 0.00 MiB above current, total RAM usage 2939.48 MiB\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "import catboost as cat\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [9] used 0.0234 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 427.29 MiB\n"
     ]
    }
   ],
   "source": [
    "def selecting_top100(predicted_prob):\n",
    "    predicted_edges = []\n",
    "    \n",
    "    for edge in predicted_prob:\n",
    "        if (edge not in predicted_edges) &\\\n",
    "        (tuple([edge[place] for place in [1,0]]) not in predicted_edges) &\\\n",
    "        (len(predicted_edges) <= 99_999):\n",
    "            predicted_edges.append(edge)\n",
    "            \n",
    "        elif (len(predicted_edges) > 99_999):\n",
    "            break\n",
    "    \n",
    "    predicted_edges = pd.DataFrame(predicted_edges, columns = ['id_1', 'id_2'])\n",
    "    return(predicted_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [10] used 0.1992 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 427.49 MiB\n"
     ]
    }
   ],
   "source": [
    "def selecting_top100_limited(predicted_prob):\n",
    "    global rec_num_of_edges, edge\n",
    "    predicted_edges = []\n",
    "    \n",
    "    for edge in predicted_prob:\n",
    "        if (edge not in predicted_edges) &\\\n",
    "        (tuple([edge[place] for place in [1,0]]) not in predicted_edges) &\\\n",
    "        (len(predicted_edges)<= 99_999) &\\\n",
    "        (rec_num_of_edges[rec_num_of_edges['id'] == edge[0]]['rec_num_of_edges'] > rec_num_of_edges[rec_num_of_edges['id'] == edge[0]]['cur_num_of_edges']).values[0] &\\\n",
    "        (rec_num_of_edges[rec_num_of_edges['id'] == edge[1]]['rec_num_of_edges'] > rec_num_of_edges[rec_num_of_edges['id'] == edge[1]]['cur_num_of_edges']).values[0]:\n",
    "            predicted_edges.append(edge)\n",
    "            rec_num_of_edges['cur_num_of_edges'] = np.where(rec_num_of_edges['id'] == edge[0], \n",
    "                                                            rec_num_of_edges['cur_num_of_edges'] + 1, \n",
    "                                                            rec_num_of_edges['cur_num_of_edges'])\n",
    "            rec_num_of_edges['cur_num_of_edges'] = np.where(rec_num_of_edges['id'] == edge[1], \n",
    "                                                            rec_num_of_edges['cur_num_of_edges'] + 1, \n",
    "                                                            rec_num_of_edges['cur_num_of_edges'])\n",
    "        elif (len(predicted_edges) > 99_999):\n",
    "            break\n",
    "            \n",
    "    predicted_edges = pd.DataFrame(predicted_edges, columns = ['id_1', 'id_2'])\n",
    "    return(predicted_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [48] used 0.0000 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 1196.82 MiB\n"
     ]
    }
   ],
   "source": [
    "def predicting(model, model_name, cat_features = True):\n",
    "    global X, predicted_edges, firm, temp, predicted_prob\n",
    "    predicted_prob = pd.DataFrame()\n",
    "    \n",
    "    if type(model).__name__ == 'CatBoostClassifier':\n",
    "        print('Check catfeatures')\n",
    "    \n",
    "    for firm in test['id']:\n",
    "        start = time.time()\n",
    "\n",
    "        temp_1 = edges[edges['id_1'] == firm]['id_2'].rename('id')\n",
    "        temp_2 = edges[edges['id_2'] == firm]['id_1'].rename('id')\n",
    "        temp = pd.DataFrame(temp_1.append(temp_2, ignore_index = True))\n",
    "        temp['is_true'] = 1\n",
    "        temp = temp.drop_duplicates()\n",
    "\n",
    "        temp = temp.append(vert_id_istrue, ignore_index = True)\n",
    "        temp = temp.drop_duplicates(subset = ['id'])\n",
    "        temp = temp.merge(vert_no_true, on = ['id'], how = 'inner')\n",
    "\n",
    "        X = temp.drop(['is_true', 'id'], axis = 'columns')\n",
    "        \n",
    "        if cat_features == True:\n",
    "            X['main_okved'] = X['main_okved'].astype(str)\n",
    "            \n",
    "        y = temp['is_true']\n",
    "        model_trained = model.fit(X, y)\n",
    "        proba = pd.DataFrame(model_trained.predict_proba(X))\n",
    "\n",
    "        proba['id_1'] = firm\n",
    "        proba['id_2'] = temp['id'].values\n",
    "        proba['is_true'] = y.values\n",
    "        predicted_prob = predicted_prob.append(proba)\n",
    "        print(firm,  time.time() - start)\n",
    "\n",
    "        del temp_1, temp_2, temp, X, y\n",
    "        gc.collect()\n",
    "        \n",
    "    predicted_prob = predicted_prob[predicted_prob['is_true'] != 1]\n",
    "    \n",
    "    ## Сортируем вершины по вероятности правдивости\n",
    "    print('sorting')\n",
    "    predicted_prob = predicted_prob.sort_values([1], ascending = False)\n",
    "    print('sorting')\n",
    "    predicted_prob = predicted_prob.sort_values([1], ascending = False)[['id_1', 'id_2']]\n",
    "    print('converting')\n",
    "    predicted_prob = [edge[1:] for edge in predicted_prob.iloc[:10_000_000,:].to_records().tolist()]\n",
    "    \n",
    "    print('Selecting top 100_000')\n",
    "    predicted_edges = selecting_top100(predicted_prob =  predicted_prob)\n",
    "\n",
    "    predicted_edges.to_csv('{}.csv'.format(model_name), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_okved</th>\n",
       "      <th>region_code</th>\n",
       "      <th>company_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.32</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63.99</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.32</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.32</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62.09</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534744</th>\n",
       "      <td>63.99</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534745</th>\n",
       "      <td>47.19</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534746</th>\n",
       "      <td>41.20</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534747</th>\n",
       "      <td>74.20</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534748</th>\n",
       "      <td>68.20</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1534749 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         main_okved  region_code  company_type\n",
       "0             49.32           77             3\n",
       "1             63.99           66             3\n",
       "2             49.32           77             2\n",
       "3             49.32           32             3\n",
       "4             62.09           23             2\n",
       "...             ...          ...           ...\n",
       "1534744       63.99           77             2\n",
       "1534745       47.19           66             2\n",
       "1534746       41.20           77             2\n",
       "1534747       74.20           33             2\n",
       "1534748       68.20           66             2\n",
       "\n",
       "[1534749 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [53] used 0.0000 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 525.04 MiB\n"
     ]
    }
   ],
   "source": [
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524354 78.79613828659058\n",
      "61537 77.85734486579895\n",
      "1142564 76.53487014770508\n",
      "300432 71.6238145828247\n",
      "83777 73.48286604881287\n",
      "206473 69.68519926071167\n",
      "58408 69.97207355499268\n",
      "776150 69.67331576347351\n",
      "1292407 74.99435520172119\n",
      "361401 76.43123722076416\n",
      "1301544 79.45202279090881\n",
      "1203323 73.70836162567139\n",
      "1209828 79.50197291374207\n",
      "341670 75.7609601020813\n",
      "83818 74.28166770935059\n",
      "1189202 77.37032771110535\n",
      "1434836 74.70625281333923\n",
      "929264 79.16014456748962\n",
      "1263393 79.7846999168396\n",
      "1342003 74.82546710968018\n",
      "1063763 72.95043897628784\n",
      "41216 76.32968592643738\n",
      "1227912 79.23151516914368\n",
      "983180 78.56292629241943\n",
      "324065 78.68760466575623\n",
      "258315 72.9852306842804\n",
      "1160709 80.99456882476807\n",
      "1443535 77.03658628463745\n",
      "214507 71.09379625320435\n",
      "1319172 81.95097160339355\n",
      "1147550 75.28863430023193\n",
      "785334 73.17656016349792\n",
      "640944 72.44754791259766\n",
      "1154568 72.21601176261902\n",
      "1427428 71.73790454864502\n",
      "409925 72.10244345664978\n",
      "1052575 70.8109290599823\n",
      "258675 69.71329998970032\n",
      "1136487 70.7328691482544\n",
      "722645 71.54952263832092\n",
      "955991 69.35029768943787\n",
      "1408687 72.21844530105591\n",
      "676805 69.42558479309082\n",
      "331678 70.61471891403198\n",
      "1378192 70.40548157691956\n",
      "1289618 68.97542381286621\n",
      "227665 71.40058946609497\n",
      "194554 70.33741092681885\n",
      "1380777 71.25956463813782\n",
      "1297265 70.55682873725891\n",
      "1292275 70.73236894607544\n",
      "1356407 69.96808242797852\n",
      "846476 70.5952467918396\n",
      "567406 70.09013676643372\n",
      "127685 74.49273252487183\n",
      "1392226 74.13369488716125\n",
      "434248 70.52448463439941\n",
      "1452068 71.41560530662537\n",
      "713665 69.46180558204651\n",
      "391589 71.3966646194458\n",
      "1487070 72.167471408844\n",
      "831789 71.18810939788818\n",
      "800360 71.44922471046448\n",
      "51755 71.54623627662659\n",
      "1500415 70.88250231742859\n",
      "596221 71.5802149772644\n",
      "641486 71.22883915901184\n",
      "1331069 72.52374362945557\n",
      "310694 70.75222492218018\n",
      "732829 71.06999182701111\n",
      "386565 68.51474475860596\n",
      "407136 71.27088761329651\n",
      "319548 71.38703417778015\n",
      "1471693 70.98144793510437\n",
      "1517903 70.53660702705383\n",
      "244691 71.44036388397217\n",
      "598328 72.56542873382568\n",
      "550468 73.71936392784119\n",
      "55389 70.3511643409729\n",
      "966969 70.85405325889587\n",
      "47929 73.40459632873535\n",
      "1439287 72.23019909858704\n",
      "936788 71.57037568092346\n",
      "995150 73.65407538414001\n",
      "1025839 73.90342020988464\n",
      "1202376 81.34092354774475\n",
      "C:\\Users\\Sibmice\\Anaconda3\\lib\\site-packages\\ipython_memory_usage\\ipython_memory_usage.py SOMETHING WEIRD HAPPENED AND THIS RAN FOR TOO LONG, THIS THREAD IS KILLING ITSELF\n",
      "89473 78.97077918052673\n",
      "1523148 77.82495355606079\n",
      "1036225 75.82960295677185\n",
      "457698 79.30314350128174\n",
      "1024638 75.39786171913147\n",
      "811809 76.54034662246704\n",
      "642175 73.87413787841797\n",
      "1392199 76.54168748855591\n",
      "1234038 76.51725220680237\n",
      "912470 77.22669100761414\n",
      "1526265 77.23335218429565\n",
      "52803 78.15701007843018\n",
      "373737 75.43486166000366\n",
      "1244877 81.24922394752502\n",
      "sorting\n",
      "sorting\n",
      "converting\n",
      "Selecting top 100_000\n",
      "In [58] used 744.8711 MiB RAM in 7650.77s, peaked 11081.86 MiB above current, total RAM usage 3626.89 MiB\n"
     ]
    }
   ],
   "source": [
    "model = VotingClassifier(\n",
    "    estimators = [('0', CatBoostClassifier(n_estimators = 100, random_state = 42, verbose = False)),\n",
    "                  ('1', CatBoostClassifier(n_estimators = 100, random_state = 322, verbose = False)),\n",
    "                  ('2', CatBoostClassifier(n_estimators = 100, random_state = 3443506946, verbose = False)),\n",
    "                  ('3', CatBoostClassifier(n_estimators = 100, random_state = 69, verbose = False)),\n",
    "                  ('4', CatBoostClassifier(n_estimators = 100, random_state = 1, verbose = False)),\n",
    "                  ('5', CatBoostClassifier(n_estimators = 100, random_state = 22, verbose = False)),\n",
    "        \n",
    "    ],\n",
    "    voting = 'soft',\n",
    ")\n",
    "model_name = 'VotingClassifier Catboost. n_estimators = 100. CPU. Full graph. As in baseline'\n",
    "predicting(model,  model_name, cat_features = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
