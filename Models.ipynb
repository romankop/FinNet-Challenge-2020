{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import igraph\n",
    "import time\n",
    "import gc\n",
    "from os import path\n",
    "import ipython_memory_usage\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'memory profile enabled'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [2] used 0.1094 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 126.67 MiB\n"
     ]
    }
   ],
   "source": [
    "%ipython_memory_usage_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [3] used 259.5664 MiB RAM in 3.06s, peaked 16.11 MiB above current, total RAM usage 386.23 MiB\n"
     ]
    }
   ],
   "source": [
    "vertices = pd.read_csv('data\\\\vertices.csv') ## вершины ребер, то есть юр.лица\n",
    "edges = pd.read_csv('data\\\\edges.csv') ## ребра графа, то есть транзакции между юр.лицами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [4] used 0.1797 MiB RAM in 0.24s, peaked 116.96 MiB above current, total RAM usage 386.41 MiB\n"
     ]
    }
   ],
   "source": [
    "vertices = vertices.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим в данные о вершинах информацию о том, представлено ли юр.лицо в тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закодируем данные о типе компании и ОКВЭД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [5] used -3.0781 MiB RAM in 0.32s, peaked 13.10 MiB above current, total RAM usage 383.34 MiB\n"
     ]
    }
   ],
   "source": [
    "my_encoder = LabelEncoder()\n",
    "vertices['company_type']= my_encoder.fit_transform(vertices['company_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Выбираем фирмыы, у которых более 1000 транзакций\n",
    "2. Из этих фирм выбираем случайныые 100 фирм\n",
    "3. У этих фирм оставляем для тренировочной выборки 500 транзакций\n",
    "4. Среди всех транзакий оставленных для тестовой выборки выбираем случайные 100 000 транзакций\n",
    "5. Пытаемся их предсказать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [6] used 355.1172 MiB RAM in 15.21s, peaked 161.73 MiB above current, total RAM usage 738.45 MiB\n"
     ]
    }
   ],
   "source": [
    "## данные о количестве транзакций для каждой фирмы\n",
    "comp_counts = edges['id_1'].append(edges['id_2'], ignore_index = True).value_counts()\n",
    "\n",
    "cv = []\n",
    "companies_cv = []\n",
    "cv_length = 3\n",
    "randoms = [13, 4444, 555]\n",
    "\n",
    "for i in range(0, cv_length):\n",
    "    cur_random = randoms[i]\n",
    "    ## выберем 100 случайных компаний, у которых транзакций более 1_000\n",
    "\n",
    "##### БЫЛИ ТОЛЬКО КОМПАНИИ С БОЛЕЕ ЧЕМ 1000 ТРАНЗАКЦИЯМИ\n",
    "    \n",
    "    sample_comp = comp_counts[comp_counts >= 1000].sample(100, random_state = cur_random).index \n",
    "    ##Выберем случайные 500 транзакций у выбаранных фирм, чтобы оставить их для обучающей выборки\n",
    "    sampled_train_edges = pd.DataFrame()\n",
    "    \n",
    "    for company in sample_comp:\n",
    "        temp_sampled = edges[(edges['id_1'] == company) | (edges['id_2'] == company)].sample(500, random_state = cur_random)\n",
    "        sampled_train_edges = sampled_train_edges.append(temp_sampled)\n",
    "    \n",
    "    ## выберем 100 000 случайных транзакций среди компаний, у которых более 700 транзакций, предварительно исключив \n",
    "    ## данные о транзакциях, оставленных для обучения\n",
    "    temp_edges = edges[edges.index.isin(sampled_train_edges.index) == False]\n",
    "    sampled_test_edges = temp_edges[temp_edges['id_1'].isin(sample_comp) | temp_edges['id_2'].isin(sample_comp)].sample(100_000, \n",
    "                                                                                                random_state = cur_random)\n",
    "    train = edges[edges.index.isin(sampled_test_edges.index) == False].index.values\n",
    "    test = sampled_test_edges.index.values\n",
    "    cv.append((train, test))\n",
    "    companies_cv.append(sample_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [7] used 2.8945 MiB RAM in 0.44s, peaked 0.00 MiB above current, total RAM usage 741.35 MiB\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "import catboost as cat\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы максимально повторить задание будем строить и оценивть модель следующим образом:\\\n",
    "1. Берем список фирм, для которых возможно удалены транзации(sample_comp)\n",
    "2. Строим список всех возможных транзакций для нашего списка фирм\n",
    "3. Удаляем из данного списка те транзакции, которые уже есть в нашей выборке\n",
    "4. Предсказываем вероятность того, что данная транзакция действительно правдива"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т.к. всего у нас 1534749 фирм, то множество всех уникальных комбинаций 1534749^2. Это слишком много, поэтому будем строить модель отдельно для каждой фирмы. Тогда количество всех комбинаций будет лишь 1534749"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [8] used 144.5547 MiB RAM in 0.22s, peaked 0.00 MiB above current, total RAM usage 885.90 MiB\n"
     ]
    }
   ],
   "source": [
    "vertices['is_true'] = 0\n",
    "vert_id_istrue = vertices[['id', 'is_true']]\n",
    "vert_no_true = vertices.drop(['is_true'], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [9] used 0.3047 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 886.21 MiB\n"
     ]
    }
   ],
   "source": [
    "def custom_cv(model, cat_features):\n",
    "    \n",
    "    ## Для кэтбуста упоминание о том, что надо проверрить категориальные фичи\n",
    "    if type(model).__name__ == 'CatBoostClassifier':\n",
    "        print('Check catfeatures')\n",
    "    \n",
    "    ## Создаем пустой вектор результатов для каждого фолда\n",
    "    cv_results = []\n",
    "    for fold in range(0,cv_length):\n",
    "        \n",
    "        ## Список всех ребер для тренировки, которые действительно существуют\n",
    "        train = edges[edges.index.isin(cv[fold][0])][['id_1', 'id_2']]\n",
    "        ## Список всех ребер для теста, которые действительно существуют\n",
    "        test = edges[edges.index.isin(cv[fold][1])][['id_1', 'id_2']]\n",
    "        ## Делаем из тестовой выборки список tuples\n",
    "        test = [edge[1:] for edge in test.to_records().tolist()]\n",
    "        \n",
    "        ## Пустой датафрейм с вероятностями для каждого ребра\n",
    "        predicted_prob = pd.DataFrame()\n",
    "        for firm in companies_cv[fold]:\n",
    "            ## таймер для подсчета времени обучения модели для 1 фирмы\n",
    "            start = time.time()\n",
    "            \n",
    "            ## Создаем список всех фирм, с которой компания имеет связи.\n",
    "            temp_1 = train[train['id_1'] == firm]['id_2'].rename('id')\n",
    "            temp_2 = train[train['id_2'] == firm]['id_1'].rename('id')\n",
    "            temp = pd.DataFrame(temp_1.append(temp_2, ignore_index = True))\n",
    "            temp['is_true'] = 1\n",
    "            temp = temp.drop_duplicates(['id', 'is_true'])\n",
    "            \n",
    "            ## Добавляем в список все фирмы, с которыми компания могла бы иметь связь\n",
    "            temp = temp.append(vert_id_istrue, ignore_index = True)\n",
    "            temp = temp.drop_duplicates(subset = ['id'])\n",
    "            temp = temp.merge(vert_no_true, on = ['id'], how = 'inner')\n",
    "\n",
    "            ## Удаляем ненужную информацию из тренировочной выборки\n",
    "            X = temp.drop(['is_true', 'id'], axis = 'columns')\n",
    "            \n",
    "            ## Для кэтбуста делаем кэтфичи\n",
    "            if cat_features == True:\n",
    "                X['main_okved'] = X['main_okved'].astype(str)  ## делаем строку\n",
    "            \n",
    "            ## target value\n",
    "            y = temp['is_true']\n",
    "            \n",
    "            \n",
    "            model_trained = model.fit(X, y)\n",
    "            proba = pd.DataFrame(model_trained.predict_proba(X))\n",
    "            \n",
    "            ## Создаем датасет с предсказанными ребрами\n",
    "            proba['id_1'] = firm\n",
    "            proba['id_2'] = temp['id'].values\n",
    "            proba['is_true'] = y.values\n",
    "            \n",
    "            ## Прикрепляем в общий датасет с предсказанными вершинами\n",
    "            predicted_prob = predicted_prob.append(proba)\n",
    "            print(firm, fold, time.time() - start)\n",
    "            \n",
    "        \n",
    "        del temp_1, temp_2, temp, X, y, train\n",
    "        gc.collect()\n",
    "        \n",
    "        ## Удаляем вершины, кооторые уже были в тренировочной выборке\n",
    "        predicted_prob = predicted_prob[predicted_prob['is_true'] != 1]\n",
    "        \n",
    "        ## Сортируем вершины по вероятности правдивости\n",
    "        predicted_prob = predicted_prob.sort_values([1], ascending = False)[['id_1', 'id_2']]\n",
    "        \n",
    "        ## Делаем из предсказанных вершин список tuples\n",
    "        predicted_prob = [edge[1:] for edge in predicted_prob.to_records().tolist()]\n",
    "        \n",
    "        ## Выбираем 100_000 самых вероятных вершин, при этом удаляя повторяющиеся\n",
    "        print('Selecting top 100_000')\n",
    "        predicted_edges = []\n",
    "        \n",
    "        for edge in predicted_prob:\n",
    "            if (edge not in predicted_edges) & (tuple([edge[place] for place in [1,0]]) not in predicted_edges) &\\\n",
    "            (len(predicted_edges) <= 99_999):\n",
    "                predicted_edges.append(edge)\n",
    "            \n",
    "            elif (len(predicted_edges) > 99_999):\n",
    "                break\n",
    "        \n",
    "        ## Подсчитываем, сколько из 100_000 предсказанных вершин действительно есть в тестовой выборке  \n",
    "        print('scoring')\n",
    "        score = 0\n",
    "        \n",
    "        for predicted_edge in predicted_edges:\n",
    "            if (predicted_edge in test) | (tuple([predicted_edge[place] for place in [1,0]]) in test):\n",
    "                score = score + 1\n",
    "        \n",
    "        del predicted_prob, test, predicted_edges\n",
    "        gc.collect()\n",
    "        \n",
    "        cv_results.append(score)\n",
    "        print(score)\n",
    "        del score\n",
    "        gc.collect()\n",
    "    return(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [10] used 0.0547 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 886.26 MiB\n"
     ]
    }
   ],
   "source": [
    "def final_results(cv, models_to_use, description, model_cols, cat_features = False):\n",
    "    names = []\n",
    "    params = []\n",
    "    scores = []\n",
    "    description = [description] * len(models_to_use)\n",
    "    model_cols = [model_cols] * len(models_to_use)\n",
    "    \n",
    "    for model in models_to_use:\n",
    "        model_score = custom_cv(model, cat_features)\n",
    "        model_score.append(np.mean(model_score))\n",
    "        scores.append(model_score)\n",
    "        \n",
    "        names.append(type(model).__name__)\n",
    "        params.append(model.get_params())\n",
    "        \n",
    "    final_results = pd.DataFrame({'model_name' : names, 'model_params' : params, \n",
    "                                  'model_description' : description, 'model_cols' : model_cols})\n",
    "    \n",
    "    for cv_split in range(1, np.array(scores).shape[1]+1):\n",
    "        final_results[str(cv_split)] = np.array(scores).T[cv_split-1]\n",
    "        \n",
    "    final_results['mean'] = final_results.iloc[:, -1]\n",
    "    final_results = final_results.drop([final_results.columns[-2]], axis = 'columns')\n",
    "    \n",
    "    if path.exists(\"final_results.csv\"):\n",
    "        final_results_loaded = pd.read_csv('final_results.csv')\n",
    "        final_results = final_results_loaded.append(final_results, ignore_index = True)    \n",
    "    final_results.to_csv('final_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_results(cv, \n",
    "             [LogisticRegression(random_state = 0, n_jobs = -1)],\n",
    "              'Full graph. As in baseline. Mean, std and sum of n_tran and value for every firm. Filled nans with 0',\n",
    "             ['main_okved', 'region_code', 'company_type'],\n",
    "             cat_features = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results(cv, \n",
    "             [LGBMClassifier(n_estimators = 100, random_state = 0, n_jobs = -1),\n",
    "              LGBMClassifier(n_estimators = 500, random_state = 0, n_jobs = -1)],\n",
    "              'Full graph. As in baseline. Mean, std and sum of n_tran and value for every firm. Filled nans with 0',\n",
    "             ['main_okved', 'region_code', 'company_type'],\n",
    "             cat_features = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_results(cv, \n",
    "             [CatBoostClassifier(n_estimators = 500, cat_features= ['main_okved', 'region_code', 'company_type'], \n",
    "                                 random_state = 0, verbose = False, task_type = 'GPU')],\n",
    "              'Full graph. As in baseline. Mean, std and sum of n_tran and value for every firm. Filled nans with 0',\n",
    "             ['main_okved', 'region_code', 'company_type'],\n",
    "             cat_features = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = pd.read_csv('final_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res.to_csv('final_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_params</th>\n",
       "      <th>model_description</th>\n",
       "      <th>model_cols</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>mean</th>\n",
       "      <th>results_leaderboard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>Full graph. As in baseline</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>4351.0</td>\n",
       "      <td>4345.0</td>\n",
       "      <td>4158.0</td>\n",
       "      <td>4284.666667</td>\n",
       "      <td>1126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>Full graph. As in baseline</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>631.0</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>663.0</td>\n",
       "      <td>808.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>{'iterations': 100, 'verbose': False, 'cat_fea...</td>\n",
       "      <td>Full graph. As in baseline</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>5765.0</td>\n",
       "      <td>5746.0</td>\n",
       "      <td>5724.0</td>\n",
       "      <td>5745.000000</td>\n",
       "      <td>4675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>Full graph. As in baseline</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>3481.0</td>\n",
       "      <td>3535.0</td>\n",
       "      <td>3266.0</td>\n",
       "      <td>3427.333333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>Full graph. As in baseline</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>19.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>47.333333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>Full graph. As in baseline</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>3868.0</td>\n",
       "      <td>4566.0</td>\n",
       "      <td>3822.0</td>\n",
       "      <td>4085.333333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>Full graph. As in baseline</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>5794.0</td>\n",
       "      <td>6073.0</td>\n",
       "      <td>5148.0</td>\n",
       "      <td>5671.666667</td>\n",
       "      <td>2149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>Full graph. As in baseline</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>2320.0</td>\n",
       "      <td>2199.0</td>\n",
       "      <td>2212.0</td>\n",
       "      <td>2243.666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>Full graph. As in baseline</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>2343.0</td>\n",
       "      <td>2425.0</td>\n",
       "      <td>2559.0</td>\n",
       "      <td>2442.333333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>Full graph. As in baseline</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>5831.0</td>\n",
       "      <td>5649.0</td>\n",
       "      <td>5351.0</td>\n",
       "      <td>5610.333333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n",
       "      <td>Full graph. As in baseline</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>104.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>Full graph. As in baseline</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>6404.0</td>\n",
       "      <td>6377.0</td>\n",
       "      <td>6010.0</td>\n",
       "      <td>6263.666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>{'iterations': 500, 'verbose': False, 'task_ty...</td>\n",
       "      <td>Full graph. As in baseline</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>7569.0</td>\n",
       "      <td>7509.0</td>\n",
       "      <td>7341.0</td>\n",
       "      <td>7473.000000</td>\n",
       "      <td>4987.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>Full graph. As in baseline</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>2670.0</td>\n",
       "      <td>2682.0</td>\n",
       "      <td>1945.0</td>\n",
       "      <td>2432.333333</td>\n",
       "      <td>4276.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>{'iterations': 500, 'verbose': False, 'task_ty...</td>\n",
       "      <td>Full graph. As in baseline</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>7318.0</td>\n",
       "      <td>7256.0</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>7233.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>{'iterations': 100, 'verbose': False, 'task_ty...</td>\n",
       "      <td>Full graph. As in baseline</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>7194.0</td>\n",
       "      <td>7167.0</td>\n",
       "      <td>7034.0</td>\n",
       "      <td>7131.666667</td>\n",
       "      <td>4917.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>Full graph. As in baseline</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>4902.0</td>\n",
       "      <td>5126.0</td>\n",
       "      <td>5118.0</td>\n",
       "      <td>5048.666667</td>\n",
       "      <td>3814.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>{'verbose': False, 'task_type': 'GPU', 'n_esti...</td>\n",
       "      <td>Full graph. As in baseline</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>7210.0</td>\n",
       "      <td>7189.0</td>\n",
       "      <td>7037.0</td>\n",
       "      <td>7145.333333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>{'verbose': False, 'task_type': 'GPU', 'n_esti...</td>\n",
       "      <td>Full graph. As in baseline</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>7160.0</td>\n",
       "      <td>7222.0</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7183.333333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>{'verbose': False, 'task_type': 'GPU', 'n_esti...</td>\n",
       "      <td>Full graph. As in baseline. Mean, std and sum ...</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>19749.0</td>\n",
       "      <td>20001.0</td>\n",
       "      <td>19894.0</td>\n",
       "      <td>19881.333333</td>\n",
       "      <td>3438.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>{'verbose': False, 'task_type': 'GPU', 'n_esti...</td>\n",
       "      <td>Full graph. As in baseline. Mean, std and sum ...</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>19763.0</td>\n",
       "      <td>20009.0</td>\n",
       "      <td>19942.0</td>\n",
       "      <td>19904.666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>{'verbose': False, 'task_type': 'GPU', 'n_esti...</td>\n",
       "      <td>Full graph. As in baseline.</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>7594.0</td>\n",
       "      <td>7619.0</td>\n",
       "      <td>7427.0</td>\n",
       "      <td>7546.666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>Full graph. As in baseline. Mean, std and sum ...</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>992.0</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>Full graph. As in baseline. Mean, std and sum ...</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>682.0</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>955.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>Full graph. As in baseline. Mean, std and sum ...</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>6279.0</td>\n",
       "      <td>7982.0</td>\n",
       "      <td>9273.0</td>\n",
       "      <td>7844.666667</td>\n",
       "      <td>588.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>{'verbose': False, 'task_type': 'GPU', 'n_esti...</td>\n",
       "      <td>Full graph. As in baseline. Mean, std and sum ...</td>\n",
       "      <td>['main_okved', 'region_code', 'company_type']</td>\n",
       "      <td>21568.0</td>\n",
       "      <td>21631.0</td>\n",
       "      <td>21470.0</td>\n",
       "      <td>21556.333333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model_name                                       model_params  \\\n",
       "0       LogisticRegression  {'C': 1.0, 'class_weight': None, 'dual': False...   \n",
       "1           LGBMClassifier  {'boosting_type': 'gbdt', 'class_weight': None...   \n",
       "2       CatBoostClassifier  {'iterations': 100, 'verbose': False, 'cat_fea...   \n",
       "3           LGBMClassifier  {'boosting_type': 'gbdt', 'class_weight': None...   \n",
       "4           LGBMClassifier  {'boosting_type': 'gbdt', 'class_weight': None...   \n",
       "5           LGBMClassifier  {'boosting_type': 'gbdt', 'class_weight': None...   \n",
       "6           LGBMClassifier  {'boosting_type': 'gbdt', 'class_weight': None...   \n",
       "7           LGBMClassifier  {'boosting_type': 'gbdt', 'class_weight': None...   \n",
       "8           LGBMClassifier  {'boosting_type': 'gbdt', 'class_weight': None...   \n",
       "9           LGBMClassifier  {'boosting_type': 'gbdt', 'class_weight': None...   \n",
       "10              GaussianNB           {'priors': None, 'var_smoothing': 1e-09}   \n",
       "11          LGBMClassifier  {'boosting_type': 'gbdt', 'class_weight': None...   \n",
       "12      CatBoostClassifier  {'iterations': 500, 'verbose': False, 'task_ty...   \n",
       "13          LGBMClassifier  {'boosting_type': 'gbdt', 'class_weight': None...   \n",
       "14      CatBoostClassifier  {'iterations': 500, 'verbose': False, 'task_ty...   \n",
       "15      CatBoostClassifier  {'iterations': 100, 'verbose': False, 'task_ty...   \n",
       "16  DecisionTreeClassifier  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...   \n",
       "17      CatBoostClassifier  {'verbose': False, 'task_type': 'GPU', 'n_esti...   \n",
       "18      CatBoostClassifier  {'verbose': False, 'task_type': 'GPU', 'n_esti...   \n",
       "19      CatBoostClassifier  {'verbose': False, 'task_type': 'GPU', 'n_esti...   \n",
       "20      CatBoostClassifier  {'verbose': False, 'task_type': 'GPU', 'n_esti...   \n",
       "21      CatBoostClassifier  {'verbose': False, 'task_type': 'GPU', 'n_esti...   \n",
       "22      LogisticRegression  {'C': 1.0, 'class_weight': None, 'dual': False...   \n",
       "23          LGBMClassifier  {'boosting_type': 'gbdt', 'class_weight': None...   \n",
       "24          LGBMClassifier  {'boosting_type': 'gbdt', 'class_weight': None...   \n",
       "25      CatBoostClassifier  {'verbose': False, 'task_type': 'GPU', 'n_esti...   \n",
       "\n",
       "                                    model_description  \\\n",
       "0                          Full graph. As in baseline   \n",
       "1                          Full graph. As in baseline   \n",
       "2                          Full graph. As in baseline   \n",
       "3                          Full graph. As in baseline   \n",
       "4                          Full graph. As in baseline   \n",
       "5                          Full graph. As in baseline   \n",
       "6                          Full graph. As in baseline   \n",
       "7                          Full graph. As in baseline   \n",
       "8                          Full graph. As in baseline   \n",
       "9                          Full graph. As in baseline   \n",
       "10                         Full graph. As in baseline   \n",
       "11                         Full graph. As in baseline   \n",
       "12                         Full graph. As in baseline   \n",
       "13                         Full graph. As in baseline   \n",
       "14                         Full graph. As in baseline   \n",
       "15                         Full graph. As in baseline   \n",
       "16                         Full graph. As in baseline   \n",
       "17                         Full graph. As in baseline   \n",
       "18                         Full graph. As in baseline   \n",
       "19  Full graph. As in baseline. Mean, std and sum ...   \n",
       "20  Full graph. As in baseline. Mean, std and sum ...   \n",
       "21                        Full graph. As in baseline.   \n",
       "22  Full graph. As in baseline. Mean, std and sum ...   \n",
       "23  Full graph. As in baseline. Mean, std and sum ...   \n",
       "24  Full graph. As in baseline. Mean, std and sum ...   \n",
       "25  Full graph. As in baseline. Mean, std and sum ...   \n",
       "\n",
       "                                       model_cols        1        2        3  \\\n",
       "0   ['main_okved', 'region_code', 'company_type']   4351.0   4345.0   4158.0   \n",
       "1   ['main_okved', 'region_code', 'company_type']    631.0   1130.0    663.0   \n",
       "2   ['main_okved', 'region_code', 'company_type']   5765.0   5746.0   5724.0   \n",
       "3   ['main_okved', 'region_code', 'company_type']   3481.0   3535.0   3266.0   \n",
       "4   ['main_okved', 'region_code', 'company_type']     19.0     83.0     40.0   \n",
       "5   ['main_okved', 'region_code', 'company_type']   3868.0   4566.0   3822.0   \n",
       "6   ['main_okved', 'region_code', 'company_type']   5794.0   6073.0   5148.0   \n",
       "7   ['main_okved', 'region_code', 'company_type']   2320.0   2199.0   2212.0   \n",
       "8   ['main_okved', 'region_code', 'company_type']   2343.0   2425.0   2559.0   \n",
       "9   ['main_okved', 'region_code', 'company_type']   5831.0   5649.0   5351.0   \n",
       "10  ['main_okved', 'region_code', 'company_type']    104.0     21.0    133.0   \n",
       "11  ['main_okved', 'region_code', 'company_type']   6404.0   6377.0   6010.0   \n",
       "12  ['main_okved', 'region_code', 'company_type']   7569.0   7509.0   7341.0   \n",
       "13  ['main_okved', 'region_code', 'company_type']   2670.0   2682.0   1945.0   \n",
       "14  ['main_okved', 'region_code', 'company_type']   7318.0   7256.0   7125.0   \n",
       "15  ['main_okved', 'region_code', 'company_type']   7194.0   7167.0   7034.0   \n",
       "16  ['main_okved', 'region_code', 'company_type']   4902.0   5126.0   5118.0   \n",
       "17  ['main_okved', 'region_code', 'company_type']   7210.0   7189.0   7037.0   \n",
       "18  ['main_okved', 'region_code', 'company_type']   7160.0   7222.0   7168.0   \n",
       "19  ['main_okved', 'region_code', 'company_type']  19749.0  20001.0  19894.0   \n",
       "20  ['main_okved', 'region_code', 'company_type']  19763.0  20009.0  19942.0   \n",
       "21  ['main_okved', 'region_code', 'company_type']   7594.0   7619.0   7427.0   \n",
       "22  ['main_okved', 'region_code', 'company_type']   1078.0   1068.0    992.0   \n",
       "23  ['main_okved', 'region_code', 'company_type']    682.0   1150.0   1033.0   \n",
       "24  ['main_okved', 'region_code', 'company_type']   6279.0   7982.0   9273.0   \n",
       "25  ['main_okved', 'region_code', 'company_type']  21568.0  21631.0  21470.0   \n",
       "\n",
       "            mean  results_leaderboard  \n",
       "0    4284.666667               1126.0  \n",
       "1     808.000000                  NaN  \n",
       "2    5745.000000               4675.0  \n",
       "3    3427.333333                  NaN  \n",
       "4      47.333333                  NaN  \n",
       "5    4085.333333                  NaN  \n",
       "6    5671.666667               2149.0  \n",
       "7    2243.666667                  NaN  \n",
       "8    2442.333333                  NaN  \n",
       "9    5610.333333                  NaN  \n",
       "10     86.000000                  NaN  \n",
       "11   6263.666667                  NaN  \n",
       "12   7473.000000               4987.0  \n",
       "13   2432.333333               4276.0  \n",
       "14   7233.000000                  NaN  \n",
       "15   7131.666667               4917.0  \n",
       "16   5048.666667               3814.0  \n",
       "17   7145.333333                  NaN  \n",
       "18   7183.333333                  NaN  \n",
       "19  19881.333333               3438.0  \n",
       "20  19904.666667                  NaN  \n",
       "21   7546.666667                  NaN  \n",
       "22   1046.000000                  NaN  \n",
       "23    955.000000                  NaN  \n",
       "24   7844.666667                588.0  \n",
       "25  21556.333333                  NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
